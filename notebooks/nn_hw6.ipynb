{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "nn_hw6.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4zxzAtJcuNi"
      },
      "source": [
        "# Домашнее задание 5\n",
        "\n",
        "Ссылка на семинар: https://colab.research.google.com/drive/1_G8kdmhtokmAUeMsSrl1IKqIs3_FEbeK?usp=sharing\n",
        "\n",
        "Не забудьте поставить видеокарту в качестве аппаратного ускорителя :)\n",
        "\n",
        "### Сохранение и загрузка\n",
        "\n",
        "[3 балла] \n",
        "\n",
        "Сделайте сохранение моделей после обучения (в формате .pth). В случае маленьких сетей на маленьких данных в этом нет необходимости, но в других случаях можно сохранять версию модели (checkpoint) каждые несколько (к примеру 5) эпох. Сделайте и протестируйте загрузку моделей для задачи классификации рукописных цифр.\n",
        "\n",
        "### Сверточная сеть на CIFAR-10\n",
        "\n",
        "[5 баллов]\n",
        "\n",
        "Решите задачу классификации на другом датасете - CIFAR-10 https://en.wikipedia.org/wiki/CIFAR-10\n",
        "В примерах к Pytorch есть полное решение этой задачи, но попробуйте придумать его самостоятельно. Этот датасет отличается от mnist тем, что изображения в нём имеют размер не 28x28, а 32x32x3, то есть они трёхканальные, \"цветные\". Для того, чтобы сеть заработала и начала хотя бы как-то учиться, нужно сделать так, чтобы размеры (shapes) тензоров на выходе предыдущего слоя совпадали с размером тензоров на входе следующего слоя.\n",
        "\n",
        "### Классификация на своих картинках\n",
        "\n",
        "[6 баллов]\n",
        "\n",
        "Запустите распознавание цифр на самостоятельно записанных данных. Можно использовать фотографию листочка, можно просто нарисовать их в пейнте. Чтобы все заработало, нужнро во-первых помнить, что сеть, созданная для работы с mnist, принимает на вход одноканальные картинки 28x28, а во-вторых учесть, что границы цифр в обучающих данных не резкие, в процессе их подготовки был применён антиалеасинг.\n",
        "\n",
        "### Загадка\n",
        "\n",
        "Доп.задача 1 [5 баллов]\n",
        "\n",
        "Найдите, почему при обучении свёрточной сети (Conv_net в семинаре) test loss всё время меньше train loss-а. Напишите, почему так получается, исправьте ошибку, если она есть. Обратите внимание, что при обучении Simple_net такого не наблюдается."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGOX-9fjcuNs"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6hdKBtIm0Lh",
        "outputId": "c1aff3e0-0cf8-4a4e-cf72-44133c1a0946"
      },
      "source": [
        "batch_size = 100\n",
        "no_cuda = False\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wBLq0YrDVJ"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, hidden, out_sz):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(28**2, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, out_sz)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.leaky_relu (x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = F.leaky_relu (x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "class Conv_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Conv_net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3, 1,padding=1)\n",
        "        self.act1=nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(6, 12, 3, 1,padding=1)\n",
        "        self.max_pool2=nn.MaxPool2d(2)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        #Flatten in forward function\n",
        "        self.fc1 = nn.Linear(16*16*12, 100)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        #self.act3 = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #torch.Size([batch_size, 3, 32, 32])\n",
        "        x = self.conv1(x)\n",
        "        #torch.Size([batch_size, 30, 32, 32])\n",
        "        x = self.act1(x)\n",
        "        x = self.conv2(x)\n",
        "        #torch.Size([batch_size,60,32,32])\n",
        "        x = self.max_pool2(x)\n",
        "        #torch.Size([batch_size, 60, 16, 16])\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        #torch.Size([batch_size, 15360])\n",
        "        x = self.fc1(x)\n",
        "        #torch.Size([batch_size, 100])\n",
        "        x = self.act2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        #torch.Size([batch_size, 10])\n",
        "        x = F.log_softmax(x,dim=1)\n",
        "        return x\n",
        "    \n",
        "    #Using Softmax only for probability predictions\n",
        "    #In training we don't really need Softmax, faster not to use it\n",
        "    def inference(self,x):\n",
        "        x = self.forward(x)\n",
        "        x = self.act3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Le_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Le_net, self).__init__()\n",
        "        #in 3*32*32\n",
        "        self.conv1 = nn.Conv2d(3, 3, 3)\n",
        "        self.conv2 = nn.Conv2d(3,6,3)\n",
        "        self.act1=nn.ReLU()\n",
        "        self.max_pool1=nn.MaxPool2d(2)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.act2 = nn.ReLU()\n",
        "        #out 6*14*14\n",
        "\n",
        "        #in 6*14*14\n",
        "        self.conv3 = nn.Conv2d(6, 6, 3)\n",
        "        self.conv4 = nn.Conv2d(6, 16, 3)\n",
        "        self.act3 = nn.ReLU()\n",
        "        self.max_pool2=nn.MaxPool2d(2)\n",
        "        self.dropout2 = nn.Dropout2d(0.25)\n",
        "        self.act4 = nn.ReLU()\n",
        "        #out 16*5*5\n",
        "\n",
        "        #Flatten in forward function\n",
        "        self.fc1 = nn.Linear(16*5*5, 100)\n",
        "        self.act5 = nn.ReLU()\n",
        "        self.dropout3 = nn.Dropout2d(0.5)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        #last activation in forward function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.max_pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.act2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.act3(x)\n",
        "        x = self.max_pool2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.act4(x)\n",
        "\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.act5(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x,dim=1)\n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuPHZ5IjPQb_"
      },
      "source": [
        "def train(model, train_dataset, epochs, optimizer):\n",
        "    model.train()\n",
        "    loss_epochs = []\n",
        "    for idx in range(epochs):\n",
        "        loss_samples = []\n",
        "        for data,target in train_dataset:\n",
        "            data=data.to(device)\n",
        "            target=target.to(device)\n",
        "            optimizer.zero_grad()   # zero the gradient buffers\n",
        "            output = model.forward(data)\n",
        "            \n",
        "            loss = F.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            loss_samples.append(loss.data.cpu().numpy())\n",
        "            optimizer.step()    # Does the update\n",
        "\n",
        "        loss_samples_mean = float(sum(loss_samples)) / len (loss_samples)\n",
        "        print(f\"Epoch {idx: >8} Loss: {loss_samples_mean}\")\n",
        "        loss_epochs.append(loss_samples_mean)\n",
        "\n",
        "    plt.plot(loss_epochs)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show() "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWP--dLjgQp9"
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    loss=0\n",
        "    accuracy = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model.forward(data)\n",
        "            loss+= F.nll_loss(output,target)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            target = target.view_as(pred)\n",
        "            for i,single_pred in enumerate(pred):\n",
        "                if single_pred == target[i]:\n",
        "                    correct+= 1\n",
        "            total += len(pred)\n",
        "    loss = loss/len(test_loader)\n",
        "    accuracy = correct / total\n",
        "    \n",
        "    print(loss)\n",
        "    print('\\n Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, total, 100. * accuracy))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox1EYkWFGJSQ"
      },
      "source": [
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "net = Le_net().to(device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "-a6h-ghjRu1c",
        "outputId": "f76d18a6-5ade-48fb-db7c-c6f1fb4336e2"
      },
      "source": [
        "#Main loop train epochs_train times and test once and\n",
        "#repeat it train_cycles times\n",
        "train_cycles=50\n",
        "epochs_train=5\n",
        "lr=0.0001\n",
        "#Main loop\n",
        "for i in range(train_cycles):\n",
        "    train(model=net, train_dataset=train_loader, epochs=epochs_train, optimizer=optim.Adam(net.parameters(), lr=lr))\n",
        "    test(model=net,device=device,test_loader=test_loader)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch        0 Loss: 2.2566394090652464\n",
            "Epoch        1 Loss: 2.083249954223633\n",
            "Epoch        2 Loss: 2.0133425080776215\n",
            "Epoch        3 Loss: 1.9664968388080597\n",
            "Epoch        4 Loss: 1.9331482992172242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(1.7774, device='cuda:0')\n",
            "\n",
            " Accuracy: 3812/10000 (38%)\n",
            "\n",
            "Epoch        0 Loss: 1.900454115629196\n",
            "Epoch        1 Loss: 1.879506786584854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-2bfc72104b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Main loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-773b575430b2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, epochs, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}